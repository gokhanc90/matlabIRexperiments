function criterion = criteriaFun(trainX2,trainY2,testX,testY)
%CRITERIAFUN Summary of this function goes here
%   Detailed explanation goes here
LabelsY=categorical(trainY2(:,3));
%Mdl = fitcknn(trainX2,LabelsY,'NumNeighbors',10,'Standardize',1,'Distance','minkowski');
%Mdl = fitcdiscr(trainX2,categorical(trainY2(:,1)));

%SVM%
% Mdl = fitcsvm(...
%     trainX2, ...
%     LabelsY, ...
%     'KernelFunction', 'polynomial', ...
%     'PolynomialOrder', 2, ...
%     'KernelScale', 'auto', ...
%     'BoxConstraint', 10, ...
%     'Standardize', true, ...
%     'ClassNames', categorical({'0'; '1'}));

% %FineTree%
% Mdl = fitctree(...
%     trainX2, ...
%     LabelsY, ...
%     'SplitCriterion', 'gdi', ...
%     'MaxNumSplits', 30, ...
%     'Surrogate', 'off', ...
%     'ClassNames', categorical({'0'; '1'}));
% % 
% %Discriminate Quadratic%
% Mdl = fitcdiscr(...
%     trainX2, ...
%     LabelsY, ...
%     'DiscrimType', 'quadratic', ...
%     'FillCoeffs', 'off', ...
%     'ClassNames', categorical({'0'; '1'}));

% 
% %Gaussian Naive Bayes%
% distributionNames =  repmat({'Normal'}, 1, size(trainX2,2));
% Mdl = fitcnb(...
%         trainX2, ...
%         LabelsY, ...
%         'DistributionNames', distributionNames, ...
%         'ClassNames', categorical({'0'; '1'}));
%  
% %Medium KNN%    
% Mdl = fitcknn(...
%     trainX2, ...
%     LabelsY, ...
%     'Distance', 'Euclidean', ...
%     'Exponent', [], ...
%     'NumNeighbors', 10, ...
%     'DistanceWeight', 'Equal', ...
%     'Standardize', true, ...
%     'ClassNames', categorical({'0'; '1'}));    
%     
% %Cubic KNN%
% Mdl = fitcknn(...
%     trainX2, ...
%     LabelsY, ...
%     'Distance', 'Minkowski', ...
%     'Exponent', 3, ...
%     'NumNeighbors', 10, ...
%     'DistanceWeight', 'Equal', ...
%     'Standardize', true, ...
%     'ClassNames', categorical({'0'; '1'}));
% 
% %Coarse%
% Mdl = fitcknn(...
%     trainX2, ...
%     LabelsY, ...
%     'Distance', 'Euclidean', ...
%     'Exponent', [], ...
%     'NumNeighbors', 100, ...
%     'DistanceWeight', 'Equal', ...
%     'Standardize', true, ...
%     'ClassNames', categorical({'0'; '1'}));
% 
% %Ensemble Subspace KNN%
subspaceDimension = max(1, min(9, size(trainX2,2) - 1));
Mdl = fitcensemble(...
    trainX2, ...
    LabelsY, ...
    'Method', 'Subspace', ...
    'NumLearningCycles', 30, ...
    'Learners', 'knn', ...
    'NPredToSample', subspaceDimension, ...
    'ClassNames', categorical({'0'; '1'}));

% 
%  %Ensemble Subspace Discriminant%
% subspaceDimension = max(1, min(9, width(trainX2) - 1));
% Mdl = fitcensemble(...
%     trainX2, ...
%     LabelsY, ...
%     'Method', 'Subspace', ...
%     'NumLearningCycles', 30, ...
%     'Learners', 'discriminant', ...
%     'NPredToSample', subspaceDimension, ...
%     'ClassNames', categorical({'0'; '1'}));
%  
%  
% %Ensemble RUSBoost%
% template = templateTree(...
%     'MaxNumSplits', 20);
% Mdl = fitcensemble(...
%     trainX2, ...
%     LabelsY, ...
%     'Method', 'RUSBoost', ...
%     'NumLearningCycles', 30, ...
%     'Learners', template, ...
%     'LearnRate', 0.1, ...
%     'ClassNames', categorical({'0'; '1'}));
%-------------------------------------------------%

[pred,ci] = predict(Mdl,testX);
if ~iscategorical(pred) 
    error('Predictions must be categorical')
end
 [ms, significant, m1, m2, oracle ] = AverageNDCG(testY,pred);


criterion=1-ms;
end

